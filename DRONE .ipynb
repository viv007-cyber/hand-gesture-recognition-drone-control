{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a844d0c0-3f43-40bc-9f5b-c5afa7c08159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6d36a9-4934-4e79-9cd0-4c51e5488617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data=pd.read_csv('/Users/rudranshrathore/Library/Mobile Documents/com~apple~Numbers/Documents/test_gesture.csv')\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b709858-04b3-4ae9-9e52-0047b96b1986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to 'augmented_hand_gesture_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load collected data\n",
    "filename = '/Users/rudranshrathore/Library/Mobile Documents/com~apple~Numbers/Documents/data6.csv'  # Change to your CSV file\n",
    "df = pd.read_csv(filename)\n",
    "df\n",
    "# Extract features (X and Y coordinates) and labels\n",
    "labels = df['label']\n",
    "X = df.drop(columns=['label']).values  # Extract X and Y coordinates\n",
    "\n",
    "# Augmentation functions\n",
    "\n",
    "def scale_coordinates(coords, scale_factor=1.1):\n",
    "    \"\"\" Scale hand landmarks by a factor \"\"\"\n",
    "    return coords * scale_factor\n",
    "\n",
    "def translate_coordinates(coords, shift_x=0.05, shift_y=0.05):\n",
    "    \"\"\" Translate hand landmarks by shifting X and Y \"\"\"\n",
    "    coords[:, ::2] += shift_x  # Shift X coordinates\n",
    "    coords[:, 1::2] += shift_y  # Shift Y coordinates\n",
    "    return coords\n",
    "\n",
    "def rotate_coordinates(coords, angle=10):\n",
    "    \"\"\" Rotate hand landmarks by an angle in degrees \"\"\"\n",
    "    angle_rad = np.radians(angle)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    X = coords[:, ::2]  # Extract X values\n",
    "    Y = coords[:, 1::2]  # Extract Y values\n",
    "    X_new = cos_a * X - sin_a * Y\n",
    "    Y_new = sin_a * X + cos_a * Y\n",
    "    coords[:, ::2] = X_new\n",
    "    coords[:, 1::2] = Y_new\n",
    "    return coords\n",
    "\n",
    "def flip_coordinates(coords):\n",
    "    \"\"\" Horizontally flip the hand landmarks (mirror effect) \"\"\"\n",
    "    coords[:, ::2] = 1 - coords[:, ::2]  # Invert X-axis values\n",
    "    return coords\n",
    "\n",
    "def add_noise(coords, noise_factor=0.02):\n",
    "    \"\"\" Add random noise to hand landmark coordinates \"\"\"\n",
    "    noise = np.random.normal(0, noise_factor, coords.shape)\n",
    "    return coords + noise\n",
    "\n",
    "# Apply augmentation techniques\n",
    "augmented_data = []\n",
    "for coords, label in zip(X, labels):\n",
    "    coords = coords.reshape(1, -1)\n",
    "    \n",
    "    augmented_data.append([label] + list(scale_coordinates(coords, 1.05).flatten()))\n",
    "    augmented_data.append([label] + list(translate_coordinates(coords, shift_x=0.02, shift_y=-0.02).flatten()))\n",
    "    augmented_data.append([label] + list(rotate_coordinates(coords, angle=15).flatten()))\n",
    "    augmented_data.append([label] + list(flip_coordinates(coords).flatten()))\n",
    "    augmented_data.append([label] + list(add_noise(coords).flatten()))\n",
    "\n",
    "# Convert augmented data to DataFrame\n",
    "augmented_df = pd.DataFrame(augmented_data, columns=df.columns)\n",
    "\n",
    "# Save augmented data to CSV\n",
    "augmented_df.to_csv('augmented_hand_gesture_data.csv', index=False)\n",
    "print(\"Augmented data saved to 'augmented_hand_gesture_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e333f1-35ca-4d2b-adad-df5d285ac8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>y11</th>\n",
       "      <th>y12</th>\n",
       "      <th>y13</th>\n",
       "      <th>y14</th>\n",
       "      <th>y15</th>\n",
       "      <th>y16</th>\n",
       "      <th>y17</th>\n",
       "      <th>y18</th>\n",
       "      <th>y19</th>\n",
       "      <th>y20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>up4</td>\n",
       "      <td>0.257461</td>\n",
       "      <td>0.840599</td>\n",
       "      <td>0.280037</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.298433</td>\n",
       "      <td>0.795164</td>\n",
       "      <td>0.297424</td>\n",
       "      <td>0.760546</td>\n",
       "      <td>0.284244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266733</td>\n",
       "      <td>0.786162</td>\n",
       "      <td>0.241204</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>0.245424</td>\n",
       "      <td>0.744192</td>\n",
       "      <td>0.252937</td>\n",
       "      <td>0.757556</td>\n",
       "      <td>0.256453</td>\n",
       "      <td>0.777565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up4</td>\n",
       "      <td>0.265201</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>0.286702</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.737299</td>\n",
       "      <td>0.303261</td>\n",
       "      <td>0.704330</td>\n",
       "      <td>0.290708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274031</td>\n",
       "      <td>0.728726</td>\n",
       "      <td>0.249719</td>\n",
       "      <td>0.712880</td>\n",
       "      <td>0.253737</td>\n",
       "      <td>0.688754</td>\n",
       "      <td>0.260893</td>\n",
       "      <td>0.701482</td>\n",
       "      <td>0.264241</td>\n",
       "      <td>0.720538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>up4</td>\n",
       "      <td>0.054138</td>\n",
       "      <td>0.822613</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.812355</td>\n",
       "      <td>0.103029</td>\n",
       "      <td>0.790915</td>\n",
       "      <td>0.110634</td>\n",
       "      <td>0.758820</td>\n",
       "      <td>0.102695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076086</td>\n",
       "      <td>0.774819</td>\n",
       "      <td>0.056703</td>\n",
       "      <td>0.753221</td>\n",
       "      <td>0.066828</td>\n",
       "      <td>0.730958</td>\n",
       "      <td>0.070446</td>\n",
       "      <td>0.745104</td>\n",
       "      <td>0.068748</td>\n",
       "      <td>0.764376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>up4</td>\n",
       "      <td>0.945862</td>\n",
       "      <td>0.822613</td>\n",
       "      <td>0.920854</td>\n",
       "      <td>0.812355</td>\n",
       "      <td>0.896971</td>\n",
       "      <td>0.790915</td>\n",
       "      <td>0.889366</td>\n",
       "      <td>0.758820</td>\n",
       "      <td>0.897305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923914</td>\n",
       "      <td>0.774819</td>\n",
       "      <td>0.943297</td>\n",
       "      <td>0.753221</td>\n",
       "      <td>0.933172</td>\n",
       "      <td>0.730958</td>\n",
       "      <td>0.929554</td>\n",
       "      <td>0.745104</td>\n",
       "      <td>0.931252</td>\n",
       "      <td>0.764376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>up4</td>\n",
       "      <td>0.914007</td>\n",
       "      <td>0.860463</td>\n",
       "      <td>0.905290</td>\n",
       "      <td>0.790165</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.781811</td>\n",
       "      <td>0.899733</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>0.899962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948562</td>\n",
       "      <td>0.766877</td>\n",
       "      <td>0.924532</td>\n",
       "      <td>0.728380</td>\n",
       "      <td>0.962955</td>\n",
       "      <td>0.731003</td>\n",
       "      <td>0.950974</td>\n",
       "      <td>0.725070</td>\n",
       "      <td>0.914531</td>\n",
       "      <td>0.736014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>right_test</td>\n",
       "      <td>0.574543</td>\n",
       "      <td>0.541358</td>\n",
       "      <td>0.548018</td>\n",
       "      <td>0.383776</td>\n",
       "      <td>0.496150</td>\n",
       "      <td>0.290670</td>\n",
       "      <td>0.438289</td>\n",
       "      <td>0.295939</td>\n",
       "      <td>0.394511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383840</td>\n",
       "      <td>0.476180</td>\n",
       "      <td>0.361811</td>\n",
       "      <td>0.560955</td>\n",
       "      <td>0.316175</td>\n",
       "      <td>0.536681</td>\n",
       "      <td>0.344246</td>\n",
       "      <td>0.542374</td>\n",
       "      <td>0.372297</td>\n",
       "      <td>0.551129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>right_test</td>\n",
       "      <td>0.499706</td>\n",
       "      <td>0.386782</td>\n",
       "      <td>0.481770</td>\n",
       "      <td>0.252749</td>\n",
       "      <td>0.439515</td>\n",
       "      <td>0.170927</td>\n",
       "      <td>0.387957</td>\n",
       "      <td>0.184525</td>\n",
       "      <td>0.352140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343971</td>\n",
       "      <td>0.346763</td>\n",
       "      <td>0.317219</td>\n",
       "      <td>0.396290</td>\n",
       "      <td>0.282328</td>\n",
       "      <td>0.394753</td>\n",
       "      <td>0.307914</td>\n",
       "      <td>0.405287</td>\n",
       "      <td>0.333792</td>\n",
       "      <td>0.406513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>right_test</td>\n",
       "      <td>0.474487</td>\n",
       "      <td>0.531072</td>\n",
       "      <td>0.464290</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.422133</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.361575</td>\n",
       "      <td>0.283485</td>\n",
       "      <td>0.321697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315861</td>\n",
       "      <td>0.477348</td>\n",
       "      <td>0.278205</td>\n",
       "      <td>0.563408</td>\n",
       "      <td>0.252850</td>\n",
       "      <td>0.535038</td>\n",
       "      <td>0.281836</td>\n",
       "      <td>0.536999</td>\n",
       "      <td>0.308879</td>\n",
       "      <td>0.544332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>right_test</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.592550</td>\n",
       "      <td>0.491585</td>\n",
       "      <td>0.459973</td>\n",
       "      <td>0.455332</td>\n",
       "      <td>0.371461</td>\n",
       "      <td>0.401534</td>\n",
       "      <td>0.374669</td>\n",
       "      <td>0.366142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370568</td>\n",
       "      <td>0.542887</td>\n",
       "      <td>0.336990</td>\n",
       "      <td>0.617233</td>\n",
       "      <td>0.319577</td>\n",
       "      <td>0.592874</td>\n",
       "      <td>0.342966</td>\n",
       "      <td>0.591650</td>\n",
       "      <td>0.364485</td>\n",
       "      <td>0.598363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>right_test</td>\n",
       "      <td>0.504598</td>\n",
       "      <td>0.583403</td>\n",
       "      <td>0.496987</td>\n",
       "      <td>0.468430</td>\n",
       "      <td>0.464150</td>\n",
       "      <td>0.391519</td>\n",
       "      <td>0.416438</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.386608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392104</td>\n",
       "      <td>0.542184</td>\n",
       "      <td>0.360550</td>\n",
       "      <td>0.600520</td>\n",
       "      <td>0.345056</td>\n",
       "      <td>0.582306</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.384249</td>\n",
       "      <td>0.587078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1463 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label        x0        x1        x2        x3        x4        x5  \\\n",
       "0            up4  0.257461  0.840599  0.280037  0.823400  0.298433  0.795164   \n",
       "1            up4  0.265201  0.780571  0.286702  0.764190  0.304222  0.737299   \n",
       "2            up4  0.054138  0.822613  0.079146  0.812355  0.103029  0.790915   \n",
       "3            up4  0.945862  0.822613  0.920854  0.812355  0.896971  0.790915   \n",
       "4            up4  0.914007  0.860463  0.905290  0.790165  0.917453  0.781811   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1458  right_test  0.574543  0.541358  0.548018  0.383776  0.496150  0.290670   \n",
       "1459  right_test  0.499706  0.386782  0.481770  0.252749  0.439515  0.170927   \n",
       "1460  right_test  0.474487  0.531072  0.464290  0.377759  0.422133  0.277108   \n",
       "1461  right_test  0.501018  0.592550  0.491585  0.459973  0.455332  0.371461   \n",
       "1462  right_test  0.504598  0.583403  0.496987  0.468430  0.464150  0.391519   \n",
       "\n",
       "            x6        x7        x8  ...       y11       y12       y13  \\\n",
       "0     0.297424  0.760546  0.284244  ...  0.266733  0.786162  0.241204   \n",
       "1     0.303261  0.704330  0.290708  ...  0.274031  0.728726  0.249719   \n",
       "2     0.110634  0.758820  0.102695  ...  0.076086  0.774819  0.056703   \n",
       "3     0.889366  0.758820  0.897305  ...  0.923914  0.774819  0.943297   \n",
       "4     0.899733  0.785039  0.899962  ...  0.948562  0.766877  0.924532   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1458  0.438289  0.295939  0.394511  ...  0.383840  0.476180  0.361811   \n",
       "1459  0.387957  0.184525  0.352140  ...  0.343971  0.346763  0.317219   \n",
       "1460  0.361575  0.283485  0.321697  ...  0.315861  0.477348  0.278205   \n",
       "1461  0.401534  0.374669  0.366142  ...  0.370568  0.542887  0.336990   \n",
       "1462  0.416438  0.396443  0.386608  ...  0.392104  0.542184  0.360550   \n",
       "\n",
       "           y14       y15       y16       y17       y18       y19       y20  \n",
       "0     0.769524  0.245424  0.744192  0.252937  0.757556  0.256453  0.777565  \n",
       "1     0.712880  0.253737  0.688754  0.260893  0.701482  0.264241  0.720538  \n",
       "2     0.753221  0.066828  0.730958  0.070446  0.745104  0.068748  0.764376  \n",
       "3     0.753221  0.933172  0.730958  0.929554  0.745104  0.931252  0.764376  \n",
       "4     0.728380  0.962955  0.731003  0.950974  0.725070  0.914531  0.736014  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1458  0.560955  0.316175  0.536681  0.344246  0.542374  0.372297  0.551129  \n",
       "1459  0.396290  0.282328  0.394753  0.307914  0.405287  0.333792  0.406513  \n",
       "1460  0.563408  0.252850  0.535038  0.281836  0.536999  0.308879  0.544332  \n",
       "1461  0.617233  0.319577  0.592874  0.342966  0.591650  0.364485  0.598363  \n",
       "1462  0.600520  0.345056  0.582306  0.365900  0.581667  0.384249  0.587078  \n",
       "\n",
       "[1463 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ad9fba-4352-4074-9247-eaad662bb2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7315, 43)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"/Users/rudranshrathore/augmented_hand_gesture_data.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe02279-7eb8-4ddb-acad-a4231b613d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = data.iloc[:, 1:].values  # Hand landmark values\n",
    "y = LabelEncoder().fit_transform(data['label'])  # Encode gesture labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2348f1ed-4adf-4d04-a536-c24e8706442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af230d7e-5335-45f5-9faa-57f7fc95a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / np.max(X_train)\n",
    "X_test = X_test / np.max(X_test)\n",
    "# Example: X_train has shape (num_samples, 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f81359-9ef2-4971-841b-1ea27989b967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09606c06-45dc-4177-81d7-d98b8bbb5547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    #tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d98907-b5b3-4d29-b31a-18c3e8f2c444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5622 - loss: 1.1036 - val_accuracy: 0.8332 - val_loss: 0.5674\n",
      "Epoch 2/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.8424 - loss: 0.4164 - val_accuracy: 0.9036 - val_loss: 0.2661\n",
      "Epoch 3/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.8993 - loss: 0.2366 - val_accuracy: 0.9029 - val_loss: 0.2171\n",
      "Epoch 4/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9102 - loss: 0.2058 - val_accuracy: 0.9234 - val_loss: 0.1825\n",
      "Epoch 5/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.9285 - loss: 0.1878 - val_accuracy: 0.8517 - val_loss: 0.3449\n",
      "Epoch 6/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9182 - loss: 0.2041 - val_accuracy: 0.9569 - val_loss: 0.1213\n",
      "Epoch 7/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9426 - loss: 0.1464 - val_accuracy: 0.9645 - val_loss: 0.1172\n",
      "Epoch 8/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9524 - loss: 0.1348 - val_accuracy: 0.9624 - val_loss: 0.1068\n",
      "Epoch 9/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.9507 - loss: 0.1282 - val_accuracy: 0.9686 - val_loss: 0.0969\n",
      "Epoch 10/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.9555 - loss: 0.1164 - val_accuracy: 0.9583 - val_loss: 0.1091\n",
      "Epoch 11/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.9503 - loss: 0.1318 - val_accuracy: 0.9323 - val_loss: 0.1456\n",
      "Epoch 12/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9479 - loss: 0.1280 - val_accuracy: 0.9556 - val_loss: 0.1104\n",
      "Epoch 13/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9515 - loss: 0.1210 - val_accuracy: 0.9747 - val_loss: 0.0825\n",
      "Epoch 14/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9615 - loss: 0.1101 - val_accuracy: 0.9494 - val_loss: 0.1199\n",
      "Epoch 15/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9541 - loss: 0.1198 - val_accuracy: 0.9774 - val_loss: 0.0791\n",
      "Epoch 16/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9654 - loss: 0.0942 - val_accuracy: 0.9706 - val_loss: 0.0837\n",
      "Epoch 17/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9634 - loss: 0.0942 - val_accuracy: 0.9740 - val_loss: 0.0893\n",
      "Epoch 18/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9640 - loss: 0.0965 - val_accuracy: 0.9706 - val_loss: 0.0785\n",
      "Epoch 19/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9662 - loss: 0.0870 - val_accuracy: 0.9651 - val_loss: 0.1125\n",
      "Epoch 20/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9592 - loss: 0.1017 - val_accuracy: 0.9740 - val_loss: 0.0844\n",
      "Epoch 21/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9640 - loss: 0.0952 - val_accuracy: 0.9740 - val_loss: 0.0685\n",
      "Epoch 22/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9760 - loss: 0.0718 - val_accuracy: 0.9535 - val_loss: 0.1139\n",
      "Epoch 23/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9699 - loss: 0.0803 - val_accuracy: 0.9836 - val_loss: 0.0622\n",
      "Epoch 24/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9710 - loss: 0.0833 - val_accuracy: 0.9822 - val_loss: 0.0599\n",
      "Epoch 25/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9668 - loss: 0.0848 - val_accuracy: 0.9768 - val_loss: 0.0750\n",
      "Epoch 26/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.9572 - loss: 0.1038 - val_accuracy: 0.9781 - val_loss: 0.0569\n",
      "Epoch 27/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0696 - val_accuracy: 0.9774 - val_loss: 0.0640\n",
      "Epoch 28/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9718 - loss: 0.0711 - val_accuracy: 0.9774 - val_loss: 0.0737\n",
      "Epoch 29/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9736 - loss: 0.0679 - val_accuracy: 0.9747 - val_loss: 0.0775\n",
      "Epoch 30/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9732 - loss: 0.0658 - val_accuracy: 0.9706 - val_loss: 0.0795\n",
      "Epoch 31/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.9784 - loss: 0.0647 - val_accuracy: 0.9815 - val_loss: 0.0484\n",
      "Epoch 32/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9738 - loss: 0.0648 - val_accuracy: 0.9836 - val_loss: 0.0485\n",
      "Epoch 33/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9734 - loss: 0.0652 - val_accuracy: 0.9747 - val_loss: 0.0496\n",
      "Epoch 34/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9776 - loss: 0.0586 - val_accuracy: 0.9768 - val_loss: 0.0513\n",
      "Epoch 35/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9779 - loss: 0.0550 - val_accuracy: 0.9829 - val_loss: 0.0460\n",
      "Epoch 36/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9749 - loss: 0.0650 - val_accuracy: 0.9617 - val_loss: 0.0848\n",
      "Epoch 37/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9777 - loss: 0.0606 - val_accuracy: 0.9829 - val_loss: 0.0398\n",
      "Epoch 38/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9794 - loss: 0.0554 - val_accuracy: 0.9836 - val_loss: 0.0404\n",
      "Epoch 39/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9734 - loss: 0.0635 - val_accuracy: 0.9809 - val_loss: 0.0487\n",
      "Epoch 40/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9762 - loss: 0.0582 - val_accuracy: 0.9795 - val_loss: 0.0489\n",
      "Epoch 41/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9750 - loss: 0.0634 - val_accuracy: 0.9829 - val_loss: 0.0462\n",
      "Epoch 42/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9727 - loss: 0.0614 - val_accuracy: 0.9836 - val_loss: 0.0424\n",
      "Epoch 43/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9730 - loss: 0.0630 - val_accuracy: 0.9829 - val_loss: 0.0450\n",
      "Epoch 44/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9762 - loss: 0.0601 - val_accuracy: 0.9768 - val_loss: 0.0624\n",
      "Epoch 45/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.9621 - loss: 0.1074 - val_accuracy: 0.9720 - val_loss: 0.0709\n",
      "Epoch 46/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9716 - loss: 0.0627 - val_accuracy: 0.9815 - val_loss: 0.0389\n",
      "Epoch 47/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9775 - loss: 0.0509 - val_accuracy: 0.9754 - val_loss: 0.0480\n",
      "Epoch 48/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9777 - loss: 0.0553 - val_accuracy: 0.9856 - val_loss: 0.0353\n",
      "Epoch 49/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9764 - loss: 0.0532 - val_accuracy: 0.9802 - val_loss: 0.0540\n",
      "Epoch 50/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9812 - loss: 0.0481 - val_accuracy: 0.9822 - val_loss: 0.0365\n",
      "Epoch 51/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9793 - loss: 0.0526 - val_accuracy: 0.9795 - val_loss: 0.0488\n",
      "Epoch 52/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9798 - loss: 0.0568 - val_accuracy: 0.9692 - val_loss: 0.0894\n",
      "Epoch 53/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9745 - loss: 0.0579 - val_accuracy: 0.9850 - val_loss: 0.0402\n",
      "Epoch 54/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9822 - loss: 0.0458 - val_accuracy: 0.9822 - val_loss: 0.0378\n",
      "Epoch 55/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.9759 - loss: 0.0565 - val_accuracy: 0.9850 - val_loss: 0.0436\n",
      "Epoch 56/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.9785 - loss: 0.0484 - val_accuracy: 0.9795 - val_loss: 0.0482\n",
      "Epoch 57/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9782 - loss: 0.0516 - val_accuracy: 0.9788 - val_loss: 0.0498\n",
      "Epoch 58/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9796 - loss: 0.0496 - val_accuracy: 0.9897 - val_loss: 0.0312\n",
      "Epoch 59/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9796 - loss: 0.0499 - val_accuracy: 0.9863 - val_loss: 0.0381\n",
      "Epoch 60/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9821 - loss: 0.0429 - val_accuracy: 0.9672 - val_loss: 0.0882\n",
      "Epoch 61/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9645 - loss: 0.0935 - val_accuracy: 0.9856 - val_loss: 0.0388\n",
      "Epoch 62/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9828 - loss: 0.0388 - val_accuracy: 0.9897 - val_loss: 0.0272\n",
      "Epoch 63/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9816 - loss: 0.0420 - val_accuracy: 0.9610 - val_loss: 0.0803\n",
      "Epoch 64/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9797 - loss: 0.0480 - val_accuracy: 0.9856 - val_loss: 0.0408\n",
      "Epoch 65/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9807 - loss: 0.0472 - val_accuracy: 0.9897 - val_loss: 0.0312\n",
      "Epoch 66/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.9848 - loss: 0.0390 - val_accuracy: 0.9863 - val_loss: 0.0417\n",
      "Epoch 67/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9866 - loss: 0.0358 - val_accuracy: 0.9774 - val_loss: 0.0569\n",
      "Epoch 68/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9715 - loss: 0.0610 - val_accuracy: 0.9877 - val_loss: 0.0272\n",
      "Epoch 69/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9855 - loss: 0.0388 - val_accuracy: 0.9891 - val_loss: 0.0316\n",
      "Epoch 70/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9810 - loss: 0.0432 - val_accuracy: 0.9843 - val_loss: 0.0322\n",
      "Epoch 71/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9857 - loss: 0.0406 - val_accuracy: 0.9911 - val_loss: 0.0253\n",
      "Epoch 72/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9806 - loss: 0.0522 - val_accuracy: 0.9877 - val_loss: 0.0338\n",
      "Epoch 73/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9860 - loss: 0.0355 - val_accuracy: 0.9850 - val_loss: 0.0395\n",
      "Epoch 74/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9804 - loss: 0.0443 - val_accuracy: 0.9788 - val_loss: 0.0479\n",
      "Epoch 75/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9742 - loss: 0.0602 - val_accuracy: 0.9925 - val_loss: 0.0232\n",
      "Epoch 76/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9863 - loss: 0.0344 - val_accuracy: 0.9781 - val_loss: 0.0503\n",
      "Epoch 77/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9823 - loss: 0.0419 - val_accuracy: 0.9829 - val_loss: 0.0376\n",
      "Epoch 78/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9829 - loss: 0.0390 - val_accuracy: 0.9918 - val_loss: 0.0232\n",
      "Epoch 79/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9852 - loss: 0.0336 - val_accuracy: 0.9891 - val_loss: 0.0267\n",
      "Epoch 80/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9868 - loss: 0.0348 - val_accuracy: 0.9843 - val_loss: 0.0379\n",
      "Epoch 81/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9834 - loss: 0.0374 - val_accuracy: 0.9856 - val_loss: 0.0342\n",
      "Epoch 82/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.9844 - loss: 0.0360 - val_accuracy: 0.9781 - val_loss: 0.0522\n",
      "Epoch 83/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9710 - loss: 0.0740 - val_accuracy: 0.9836 - val_loss: 0.0396\n",
      "Epoch 84/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9844 - loss: 0.0385 - val_accuracy: 0.9877 - val_loss: 0.0434\n",
      "Epoch 85/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9881 - loss: 0.0309 - val_accuracy: 0.9925 - val_loss: 0.0211\n",
      "Epoch 86/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9864 - loss: 0.0306 - val_accuracy: 0.9870 - val_loss: 0.0282\n",
      "Epoch 87/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9864 - loss: 0.0337 - val_accuracy: 0.9733 - val_loss: 0.0739\n",
      "Epoch 88/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9817 - loss: 0.0416 - val_accuracy: 0.9747 - val_loss: 0.0552\n",
      "Epoch 89/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9842 - loss: 0.0389 - val_accuracy: 0.9932 - val_loss: 0.0200\n",
      "Epoch 90/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9850 - loss: 0.0324 - val_accuracy: 0.9850 - val_loss: 0.0394\n",
      "Epoch 91/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9793 - loss: 0.0449 - val_accuracy: 0.9938 - val_loss: 0.0194\n",
      "Epoch 92/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9870 - loss: 0.0309 - val_accuracy: 0.9904 - val_loss: 0.0266\n",
      "Epoch 93/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0255 - val_accuracy: 0.9911 - val_loss: 0.0204\n",
      "Epoch 94/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9862 - loss: 0.0333 - val_accuracy: 0.9945 - val_loss: 0.0205\n",
      "Epoch 95/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9793 - loss: 0.0434 - val_accuracy: 0.9925 - val_loss: 0.0239\n",
      "Epoch 96/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9862 - loss: 0.0334 - val_accuracy: 0.9938 - val_loss: 0.0208\n",
      "Epoch 97/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9879 - loss: 0.0268 - val_accuracy: 0.9911 - val_loss: 0.0185\n",
      "Epoch 98/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9880 - loss: 0.0330 - val_accuracy: 0.9918 - val_loss: 0.0234\n",
      "Epoch 99/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9831 - loss: 0.0376 - val_accuracy: 0.9911 - val_loss: 0.0295\n",
      "Epoch 100/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9855 - loss: 0.0390 - val_accuracy: 0.9856 - val_loss: 0.0370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x321cdfda0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,batch_size=64, epochs=100, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885fd59f-7917-41b0-8c45-57b04bb0c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9850 - loss: 0.0434\n",
      "Neural Network Accuracy: 0.9856459498405457\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Neural Network Accuracy: {accuracy:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0787734d-7989-495f-ad1c-6e551a519127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#import mediapipe as mp\n",
    "#import tensorflow as tf\n",
    "#import numpy as np#\n",
    "\n",
    "#model = tf.keras.models.load_model(\"gesture_model.h5\")#\n",
    "\n",
    "## Initialize MediaPipe Hands\n",
    "#mp_hands = mp.solutions.hands\n",
    "#hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.8)\n",
    "#mp_draw = mp.solutions.drawing_utils#\n",
    "\n",
    "#cap = cv2.VideoCapture(0)#\n",
    "\n",
    "#def preprocess_landmarks(landmarks):\n",
    "#    landmarks = np.array(landmarks).reshape(1, -1)\n",
    "#    return landmarks#\n",
    "\n",
    "#gesture_labels = ['down', 'left', 'right', 'up']  # Example labels#\n",
    "\n",
    "#while cap.isOpened():\n",
    "#    ret, frame = cap.read()\n",
    "#    if not ret:\n",
    "#        break\n",
    "#    frame=cv2.flip(frame, 1)#\n",
    "\n",
    "#    # Convert frame to RGB\n",
    "#    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#    result = hands.process(frame_rgb)#\n",
    "\n",
    "#    if result.multi_hand_landmarks:\n",
    "#        for hand_landmarks in result.multi_hand_landmarks:\n",
    "#            landmarks = []\n",
    "#            for lm in hand_landmarks.landmark:\n",
    "#                landmarks.extend([lm.x, lm.y, lm.z])##\n",
    "\n",
    "#            # Preprocess landmarks\n",
    "#            landmarks = preprocess_landmarks(landmarks)#\n",
    "\n",
    "#            # Make prediction using the trained model\n",
    "#            gesture = model.predict(landmarks)\n",
    "#            predicted_label = gesture[0]#\n",
    "\n",
    "#            # Map the numeric label to gesture name\n",
    "#            predicted_label = np.argmax(gesture)  # Get index of the highest probability#\n",
    "\n",
    "#            predicted_gesture = gesture_labels[predicted_label]#\n",
    "\n",
    "#            # Display prediction\n",
    "#            cv2.putText(frame, f\"Predicted Gesture: {predicted_gesture}\", (10, 30),\n",
    "#                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)#\n",
    "\n",
    "#            # Draw landmarks on frame\n",
    "#            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)#\n",
    "\n",
    "#    cv2.imshow(\"Real-time Gesture Recognition\", frame)#\n",
    "\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#        break#\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f245992-88ad-4568-a03f-f3534d78aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#df=pd.read_csv(\"/Users/rudranshrathore/gesture_up4.csv\")\n",
    "##def scale_landmarks(df, scale_factor_range=(0.8, 1.2)):\n",
    "##    scale_factor = np.random.uniform(*scale_factor_range)\n",
    "##    df_scaled = df * scale_factor\n",
    "##    return df_scaled\n",
    "##df_aug=scale_landmarks(df)\n",
    "#df.head()\n",
    "#df.fillna(0, inplace=True)\n",
    "#df = df.astype(float)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8688641-fd68-4b84-98e8-fce935afb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a random scale factor between 0.8 and 1.2\n",
    "#scale_factor = np.random.uniform(0.8, 1.2)\n",
    "#\n",
    "## Apply scaling to all columns (x, y, z coordinates)\n",
    "#df_scaled = df * scale_factor\n",
    "#\n",
    "## Save scaled data\n",
    "#df_scaled.to_csv('scaled_landmarks.csv', index=False)\n",
    "#print(\"Scaling applied and saved to 'scaled_landmarks.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ca8ee6-822e-4447-8bf1-335603667116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rotate_landmarks(df, angle_range=(-15, 15)):\n",
    "#    angle = np.radians(np.random.uniform(*angle_range))\n",
    "#    cos_val, sin_val = np.cos(angle), np.sin(angle)\n",
    "#\n",
    "#    df_rotated = df.copy()\n",
    "#    for i in range(0, len(df.columns), 3):  # Only modify x and y columns\n",
    "#        x = df.iloc[:, i].values\n",
    "#        y = df.iloc[:, i+1].values\n",
    "#        \n",
    "#        df_rotated.iloc[:, i] = cos_val * x - sin_val * y  # x' = cosθ * x - sinθ * y\n",
    "#        df_rotated.iloc[:, i+1] = sin_val * x + cos_val * y  # y' = sinθ * x + cosθ * y\n",
    "#\n",
    "#    return df_rotated\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3f7399-dcaa-4cc6-af29-76e6ba526ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def add_noise(df, noise_std=0.02):\n",
    "#    noise = np.random.normal(0, noise_std, df.shape)\n",
    "#    df_noisy = df + noise\n",
    "#    return df_noisy\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b252e3c0-07ac-4369-8d44-32398e5e2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mirror_landmarks(df):\n",
    "#    df_mirrored = df.copy()\n",
    "#    for i in range(0, len(df.columns), 3):\n",
    "#        df_mirrored.iloc[:, i] = -df.iloc[:, i]  # Invert x-coordinates (mirror effect)\n",
    "#    return df_mirrored#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8322084-cf8d-4eb8-a8df-017ba4417161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def augment_data(csv_path, augmentations=5):\n",
    "#    df = pd.read_csv(csv_path)\n",
    "#\n",
    "#    augmented_data = []\n",
    "#    for _ in range(augmentations):\n",
    "#        df_aug = df.copy()\n",
    "#        df_aug = scale_landmarks(df_aug)\n",
    "#        df_aug = translate_landmarks(df_aug)\n",
    "#        df_aug = rotate_landmarks(df_aug)\n",
    "#        df_aug = add_noise(df_aug)\n",
    "#        df_aug = mirror_landmarks(df_aug)\n",
    "#        \n",
    "#        augmented_data.append(df_aug)\n",
    "#    \n",
    "#    df_augmented = pd.concat(augmented_data, ignore_index=True)\n",
    "#    df_augmented.to_csv('augmented_landmarks.csv', index=False)\n",
    "#    print(\"Augmented data saved to augmented_landmarks.csv\")\n",
    "#\n",
    "#augment_data(\"/Users/rudranshrathore/gesture_up4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2f9fcb-2062-4b13-a459-3ccdfcc32a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1743590379.601778 1100445 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "W0000 00:00:1743590379.622006 1114391 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743590379.629217 1114391 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('gesture_model.h5')\n",
    "\n",
    "# Load MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Define gesture labels (ensure these match the trained model's labels)\n",
    "gesture_labels = ['right', 'down', 'left', 'up']  # Update with your gestures\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(gesture_labels)\n",
    "\n",
    "def recognize_gesture():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb_frame)\n",
    "\n",
    "        # Default labels if hands are not detected\n",
    "        left_hand_label = \"No Hand Detected\"\n",
    "        right_hand_label = \"No Hand Detected\"\n",
    "\n",
    "        if result.multi_hand_landmarks and result.multi_handedness:\n",
    "            for idx, hand_landmarks in enumerate(result.multi_hand_landmarks):\n",
    "                handedness = result.multi_handedness[idx].classification[0].label\n",
    "\n",
    "                # Extract x, y, z coordinates (21 landmarks * 3 values)\n",
    "                landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "                # Convert to NumPy array and reshape for model input\n",
    "                landmarks = np.array([landmarks])\n",
    "\n",
    "                # Predict gesture\n",
    "                prediction = model.predict(landmarks)\n",
    "                predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])[0]\n",
    "\n",
    "                # Assign label to left or right hand based on classification\n",
    "                if handedness == \"Left\":\n",
    "                    left_hand_label = predicted_label\n",
    "                elif handedness == \"Right\":\n",
    "                    right_hand_label = predicted_label\n",
    "\n",
    "                # Draw hand landmarks on the frame\n",
    "                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the recognized gestures on the screen\n",
    "        cv2.putText(frame, f\"Left Hand : {left_hand_label}\", (10, 50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f\"Right Hand: {right_hand_label}\", (frame.shape[1] - 300, 50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Hand Gesture Recognition', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "recognize_gesture()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "749b0a78-232e-4490-9c37-5f8e923edb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "302847f4-ab75-49dd-b914-485fb66b0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"AIzaSyD2TAFoTdUL3yyhU8rZJYsOwlPNbm2ZZxA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2b5feea1-3bf3-48eb-a2d2-c2ea8c25f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-2.0-flash-exp\",\n",
    "  generation_config=generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0abce7d5-fb7c-4eb0-b1fc-3b02d651bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please say something...\n",
      "Audio recorded.\n",
      "Sorry, I couldn't understand the audio.\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m record_audio() \n\u001b[1;32m     24\u001b[0m recognize_audio(audio_data) \n\u001b[0;32m---> 25\u001b[0m question\u001b[38;5;241m=\u001b[39m\u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:262\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    255\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[1;32m    256\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[1;32m    260\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[1;32m    261\u001b[0m )\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[0;34m(self, response_text)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[0;34m(response_text)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[0;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def record_audio():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Please say something...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)  \n",
    "        audio_data = recognizer.listen(source)  \n",
    "        print(\"Audio recorded.\")\n",
    "        return audio_data \n",
    "\n",
    "def recognize_audio(audio_data):\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I couldn't understand the audio.\")\n",
    "    except sr.RequestError:\n",
    "        print(\"Could not request results from Google Speech Recognition service.\")\n",
    "\n",
    "\n",
    "audio_data = record_audio() \n",
    "recognize_audio(audio_data) \n",
    "question=recognizer.recognize_google(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42878f4-7277-4c6b-8296-56d659b62c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\"Follow these instructions strictly:\n",
    "\n",
    "Determine if the given question can be answered with a direct 'Yes' or 'No'.\n",
    "If the question can be answered this way, provide either 'Yes' or 'No'.\n",
    "If the question requires explanation or cannot be answered with 'Yes' or 'No', respond with 'None'.\n",
    "Do not include any explanations, reasoning, or additional words.\n",
    "Examples:\n",
    "\n",
    "Q: Is the sun hot? → Yes\n",
    "Q: What is your name? → None\n",
    "Q: Are dogs mammals? → Yes\n",
    "Strictly follow the format and avoid adding any extra text.\n",
    "The question is {question}, now answer accordingly\"*\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59026a6-d5d2-42ec-8fd3-e299650b1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=model.generate_content(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cdc78-705f-422d-a377-14341bd36597",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=response.text\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fa57b-e213-4e64-b087-a4776c6d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On the basis of Yes or No control drone movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1b3ef-5e63-44f3-9f81-ba37583c9f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af2fd9-8522-482d-9717-57505547d9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
